{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8c5778-206a-4b43-9694-ad419f5add4b",
   "metadata": {},
   "source": [
    "# Machine Learning Project 2: Spam Detection -- Application of Naive Baysian Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb62d02-cea2-4c20-af4b-f4a1382b252a",
   "metadata": {},
   "source": [
    "#### Project description:\n",
    "In this project, we are going to perform classification for the purpose of spam detection. Naive Baysian Theorem will be used to calculate the probability of emails falling into the spam categoty. Therefore at the end, we could input our own messages and compute their probability of being spam. The dataset used for analysis here is collected from online learning platform Coursera and it contains 5728 sample emails indexed as either 1 or 0 (1 represents spam, 0 represents non-spam). Hope this could give an insight into email security and enhance user satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7960663-fb21-4b28-96ad-c21efb2c59f3",
   "metadata": {},
   "source": [
    "### 1. Naive Baysian Theorem formula review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b4c6b-ff8f-4f43-b11e-05a1dd15d1cb",
   "metadata": {},
   "source": [
    "$$ P(\\text{spam}|\\text{word}) = \\frac{P(\\text{word}|\\text{spam}) \\cdot P(\\text{spam})}{P(\\text{word}|\\text{spam}) \\cdot P(\\text{spam}) + P(\\text{word}|\\text{ham}) \\cdot P(\\text{ham})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be2e148-75f4-4ef8-983d-0bceb97e6e14",
   "metadata": {},
   "source": [
    "One can further expand the above formula into the following version:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b80d22-6705-4449-be91-a99ce9275c39",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$ P(\\text{spam}|\\text{word}) = \\frac{P(\\text{word}_{1}|\\text{spam}) \\cdot P(\\text{word}_{2}|\\text{spam}) \\cdot \\cdot \\cdot P(\\text{word}_{n}|\\text{spam}) \\cdot P(\\text{spam})} {P(\\text{word}_{1}|\\text{spam}) \\cdot P(\\text{word}_{2}|\\text{spam}) \\cdot \\cdot \\cdot P(\\text{word}_{n}|\\text{spam}) \\cdot P(\\text{spam}) + P(\\text{word}_{1}|\\text{ham}) \\cdot P(\\text{word}_{2}|\\text{ham}) \\cdot \\cdot \\cdot P(\\text{word}_{n}|\\text{ham}) \\cdot P(\\text{ham}) \\cdot P(\\text{ham})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d703db-299b-438b-b6c6-405a735d4500",
   "metadata": {},
   "source": [
    "In this case, what we need to calculate is the probability of an email being spam given a particular group of given words. The n number of events in both numerator and denominator are considered disjoint or independent. Ham means non-spam. We will base our analysis on this formula. The methodology in this project is to code each part of this formula to compute probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350176d5-8843-4abb-b928-b712f9006b4d",
   "metadata": {},
   "source": [
    "### 2. Load libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc883f38-ecce-47e3-a899-1c9180a37be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a82e5601-4778-428a-8124-afd41407c0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                    text  spam\n",
      "0     Subject: naturally irresistible your corporate...     1\n",
      "1     Subject: the stock trading gunslinger  fanny i...     1\n",
      "2     Subject: unbelievable new homes made easy  im ...     1\n",
      "3     Subject: 4 color printing special  request add...     1\n",
      "4     Subject: do not have money , get software cds ...     1\n",
      "...                                                 ...   ...\n",
      "5723  Subject: re : research and development charges...     0\n",
      "5724  Subject: re : receipts from visit  jim ,  than...     0\n",
      "5725  Subject: re : enron case study update  wow ! a...     0\n",
      "5726  Subject: re : interest  david ,  please , call...     0\n",
      "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0\n",
      "\n",
      "[5728 rows x 2 columns]>\n",
      "<bound method NDFrame.tail of                                                    text  spam\n",
      "0     Subject: naturally irresistible your corporate...     1\n",
      "1     Subject: the stock trading gunslinger  fanny i...     1\n",
      "2     Subject: unbelievable new homes made easy  im ...     1\n",
      "3     Subject: 4 color printing special  request add...     1\n",
      "4     Subject: do not have money , get software cds ...     1\n",
      "...                                                 ...   ...\n",
      "5723  Subject: re : research and development charges...     0\n",
      "5724  Subject: re : receipts from visit  jim ,  than...     0\n",
      "5725  Subject: re : enron case study update  wow ! a...     0\n",
      "5726  Subject: re : interest  david ,  please , call...     0\n",
      "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0\n",
      "\n",
      "[5728 rows x 2 columns]>\n",
      "Index(['text', 'spam'], dtype='object')\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "emails=pd.read_csv(\"emails.csv\")\n",
    "print(emails.head)\n",
    "print(emails.tail)\n",
    "print(emails.columns)\n",
    "print(emails.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66588690-a6a2-4b75-8998-17eaf6a8fc9f",
   "metadata": {},
   "source": [
    "### 3. Process dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dfcf5d-ab62-4606-8885-3c60be4a5ff1",
   "metadata": {},
   "source": [
    "In this section we will process the dataset for the convenience of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37473898-cd95-4614-85cf-23717ccc2069",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxy\\AppData\\Local\\Temp\\ipykernel_23508\\1252451023.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emails[\"words\"][i]=list(set(subject.split()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                    text  spam  \\\n",
      "0     Subject: naturally irresistible your corporate...     1   \n",
      "1     Subject: the stock trading gunslinger  fanny i...     1   \n",
      "2     Subject: unbelievable new homes made easy  im ...     1   \n",
      "3     Subject: 4 color printing special  request add...     1   \n",
      "4     Subject: do not have money , get software cds ...     1   \n",
      "...                                                 ...   ...   \n",
      "5723  Subject: re : research and development charges...     0   \n",
      "5724  Subject: re : receipts from visit  jim ,  than...     0   \n",
      "5725  Subject: re : enron case study update  wow ! a...     0   \n",
      "5726  Subject: re : interest  david ,  please , call...     0   \n",
      "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0   \n",
      "\n",
      "                                                  words  \n",
      "0     [aim, formats, easy, ;, creativeness, ieader, ...  \n",
      "1     [edt, slung, hawthorn, incredible, hepburn, gr...  \n",
      "2     [credit, fixed, homeowner, opportunity, easy, ...  \n",
      "3     [message, (, a, ramsey, advertisement, or, 338...  \n",
      "4     [tradgedies, by, old, ended, it, here, be, all...  \n",
      "...                                                 ...  \n",
      "5723  [et, i, there, 10, entry, $, here, kaminski, 0...  \n",
      "5724  [i, out, all, department, finance, at, kaminsk...  \n",
      "5725  [i, out, drop, 10, week, lay, ken, 04, 01, goo...  \n",
      "5726  [i, kaminski, interest, discipline, 2000, have...  \n",
      "5727  [entire, database, department, model, www, at,...  \n",
      "\n",
      "[5728 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "emails[\"words\"]=0  #initialization\n",
    "for i in range(len(emails)):\n",
    "    email=emails[\"text\"].values\n",
    "    subject=str(email[i]).lower()\n",
    "    emails[\"words\"][i]=list(set(subject.split()))\n",
    "print(emails.head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c157c97-efcf-4cef-84b7-5335373fde00",
   "metadata": {},
   "source": [
    "This aim of adding one new column with words exactly the same as those in the column \"text\" but are non-capitalized and non-repetitive is to ensure that the same words with spelling variations (e.g. \"Money\",\"money\",\"MONEY\") will all be converted into the lowercased version (only \"money\" in this case) and will only appear once. This could further make sure each word will be counted only once, leading to the accurate anlysis result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a0ce7-a79f-4d5c-885d-73c20f824173",
   "metadata": {},
   "source": [
    "### 4. Calculate P(spam) and P(ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e657532-cc78-469a-a39e-6d4f4e1b576a",
   "metadata": {},
   "source": [
    "Let's start with the simplest part of the above Naive Baysian Theorem: P(spam) and P(ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c022c8-e16c-4dd7-ad7f-9254bd77f035",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of emails which are spam is  1368\n",
      "The number of emails which are ham is  4360\n"
     ]
    }
   ],
   "source": [
    "spam_number=len(emails[emails[\"spam\"]==1])\n",
    "ham_number=len(emails[emails[\"spam\"]==0])\n",
    "print(\"The number of emails which are spam is \",spam_number)\n",
    "print(\"The number of emails which are ham is \",ham_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa445e5c-0ab4-4cd4-b2dd-c8e1e1cea57c",
   "metadata": {},
   "source": [
    "The we need to calculate probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74a331ee-8240-4c41-b22d-1bc06075a92d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of emails which are spam is 23.88%\n",
      "The proportion of emails which are ham is 76.12% \n"
     ]
    }
   ],
   "source": [
    "spam_prop=round(spam_number/len(emails),4)\n",
    "ham_prop=round(ham_number/len(emails),4)\n",
    "print(f\"The proportion of emails which are spam is {spam_prop*100:.2f}%\")\n",
    "print(f\"The proportion of emails which are ham is {ham_prop*100:.2f}% \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841f13d-f0ea-479d-a421-8d2a8f747ffc",
   "metadata": {},
   "source": [
    "### 5. Calculate P(word|spam) and P(word|ham) for input messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec45f3-50de-41a5-bf9a-4eae68d8e418",
   "metadata": {},
   "source": [
    "In order to calculate the probability of a word given it is in spam and the probability of a word given it is in ham, we need to know the frequency of each word appearing in the emails that are either spam or ham. Therefore, we could create a dictionary looks roughly like this: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2d293-ed78-4442-9147-08440caea38f",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$ \\{\"money\":\\{\"spam\":567,\"ham\":345\\}, \n",
    " \"lottery\":\\{\"spam\":123,\"ham\":456\\}....\\} (this is just an example) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "672befb5-0bed-49e8-b602-e1b4f663f070",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject:': {'spam': 1368, 'ham': 4360}, '.': {'spam': 1336, 'ham': 4322}, 'to': {'spam': 1161, 'ham': 4056}, ',': {'spam': 1158, 'ham': 4142}, 'the': {'spam': 1083, 'ham': 3999}}\n",
      "The frequncy of word 'money' being spam and ham: {'spam': 280, 'ham': 87}\n",
      "The frequncy of word 'million' being spam and ham: {'spam': 102, 'ham': 71}\n",
      "The frequncy of word 'tomorrow' being spam and ham: {'spam': 11, 'ham': 234}\n",
      "This word doesn't exist in the library! Please try other words!\n"
     ]
    }
   ],
   "source": [
    "word_freq_dictionary={}\n",
    "email_words=emails[\"words\"].values\n",
    "for words_list,row in zip(email_words,emails[\"spam\"].index):\n",
    "    for word in words_list:\n",
    "        if word not in word_freq_dictionary:\n",
    "            word_freq_dictionary[word]={\"spam\":0,\"ham\":0}\n",
    "    \n",
    "        if emails[\"spam\"][row]==1:\n",
    "            word_freq_dictionary[word][\"spam\"]+=1\n",
    "        else:\n",
    "            word_freq_dictionary[word][\"ham\"]+=1\n",
    "\n",
    "# let me only display the first five items in the dictionary since it will be too lengthy to display all\n",
    "top_items = dict(sorted(word_freq_dictionary.items(), key=lambda x: x[1]['spam'], reverse=True)[:5])\n",
    "print(top_items)\n",
    "\n",
    "# let's try some words\n",
    "print(f\"The frequncy of word 'money' being spam and ham: {word_freq_dictionary['money']}\")\n",
    "print(f\"The frequncy of word 'million' being spam and ham: {word_freq_dictionary['million']}\")\n",
    "print(f\"The frequncy of word 'tomorrow' being spam and ham: {word_freq_dictionary['tomorrow']}\")\n",
    "\n",
    "# for some words that may not appear in the dictionary\n",
    "try:\n",
    "    word_freq_dictionary['wefqwfef']\n",
    "except KeyError:\n",
    "    print(\"This word doesn't exist in the library! Please try other words!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ffa5db-ff67-40a5-b2c6-1b8baae0fcf0",
   "metadata": {},
   "source": [
    "Since we have already figured out the frequency of each word being spam or ham, we could expand $$ P(\\text{word}|\\text{spam})$$ into $$ P(\\text{word}_{1}|\\text{spam}) \\cdot P(\\text{word}_{2}|\\text{spam}) \\cdot \\cdot \\cdot P(\\text{word}_{n}|\\text{spam}) $$\n",
    "and expand $$ P(\\text{word}|\\text{ham})$$ into $$ P(\\text{word}_{1}|\\text{ham}) \\cdot P(\\text{word}_{2}|\\text{ham}) \\cdot \\cdot \\cdot P(\\text{word}_{n}|\\text{ham}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc08c6-e950-4964-adc3-4c34cd6e7f52",
   "metadata": {},
   "source": [
    "Moreover, it's more convenient here for us to write a function to prevent repeating writing a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f841fd7-643f-4992-90f1-4b7a801cb9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prop_word_given_spam_or_ham(text):\n",
    "    text=text.lower()\n",
    "    text=set(text.split())\n",
    "    prop_word_given_spam=1 #initialization\n",
    "    prop_word_given_ham=1 #initialization\n",
    "    for word in text:\n",
    "        if word in word_freq_dictionary:\n",
    "            prop_word_given_spam*=word_freq_dictionary[word][\"spam\"]/spam_number\n",
    "            prop_word_given_ham*=word_freq_dictionary[word][\"ham\"]/ham_number\n",
    "    final_prop_word_given_spam=prop_word_given_spam\n",
    "    final_prop_word_given_ham=prop_word_given_ham\n",
    "    \n",
    "    return final_prop_word_given_spam,final_prop_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd64733-9a47-47b5-912d-0690b3ff589f",
   "metadata": {},
   "source": [
    "### 6. Calculate P(spam|word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42da25a7-1bfb-4d0a-9d6e-64b11682f164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prop_spam_word(final_prop_word_given_spam,final_prop_word_given_ham):\n",
    "    prop_spam_given_word=(final_prop_word_given_spam*spam_prop)/((final_prop_word_given_spam*spam_prop)+(final_prop_word_given_ham*ham_prop))\n",
    "    return prop_spam_given_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d98fb8f-36fb-4b99-847f-9b02573d1027",
   "metadata": {},
   "source": [
    "Alternatively, we can actually combine these two functions together into on for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9cd6cd0c-b45d-415f-a0ff-d2e59011cae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prop_word_given_spam_or_ham(text):\n",
    "    text=text.lower()\n",
    "    text=set(text.split())\n",
    "    prop_word_given_spam=1 #initialization\n",
    "    prop_word_given_ham=1 #initialization\n",
    "    for word in text:\n",
    "        if word in word_freq_dictionary:\n",
    "            prop_word_given_spam*=word_freq_dictionary[word][\"spam\"]/spam_number\n",
    "            prop_word_given_ham*=word_freq_dictionary[word][\"ham\"]/ham_number\n",
    "    final_prop_word_given_spam=prop_word_given_spam\n",
    "    final_prop_word_given_ham=prop_word_given_ham\n",
    "    prop_spam_given_word=(final_prop_word_given_spam*spam_prop)/((final_prop_word_given_spam*spam_prop)+(final_prop_word_given_ham*ham_prop))\n",
    "    \n",
    "    return prop_spam_given_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3441f1e5-bfab-46d3-8469-4755c8ae1ee5",
   "metadata": {},
   "source": [
    "### 7. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70e6f6-f316-478a-8e4e-e0b012eb5237",
   "metadata": {},
   "source": [
    "##### Let's randomly input some messages and check whether the model works well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "578209b9-af24-40f3-84dd-4a914601e08e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of message1 being spam is 98.60%\n",
      "The probability of message2 being spam is 15.38%\n",
      "The probability of message3 being spam is 0.33%\n",
      "The probability of message4 being spam is 100.00%\n",
      "The probability of message5 being spam is 93.97%\n"
     ]
    }
   ],
   "source": [
    "message1=\"Check this email out right away! Otherwise you will lose chance of being a millionaire! Let's make money together.\"\n",
    "message2=\"Check the link down below to learn how to learn data science and land a job as a data scientist.\"\n",
    "message3=\"According to the weather forecast, it will being raining tomorrow.\"\n",
    "message4=\"Dear student! Tomorrow will be the deadline. Please submit your homework to the website ASAP!\"\n",
    "\n",
    "# and here is the funny one. My Polish friend told me there used to be one type of popular but quite obvious scam message, but some people still fell into prey.\n",
    "message5=\"Hello! I am King Charles I, and I'm actualy still alive. I have a large sum of money that no one wants to inherit.\\n\" +\\\n",
    "\"I want you to be my heir. Please open the link down below and put into your bank account number and password right now. You will earn a billion\\n\"+\\\n",
    "\"and get rich. Make sure do it within today, otherwise you will lose chance!\"\n",
    "\n",
    "print(f\"The probability of message1 being spam is {prop_word_given_spam_or_ham(message1)*100:.2f}%\")\n",
    "print(f\"The probability of message2 being spam is {prop_word_given_spam_or_ham(message2)*100:.2f}%\")\n",
    "print(f\"The probability of message3 being spam is {prop_word_given_spam_or_ham(message3)*100:.2f}%\")\n",
    "print(f\"The probability of message4 being spam is {prop_word_given_spam_or_ham(message4)*100:.2f}%\")\n",
    "print(f\"The probability of message5 being spam is {prop_word_given_spam_or_ham(message5)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78cf13-d7e2-45ac-a00d-2fc5df252cc1",
   "metadata": {},
   "source": [
    "##### It seems the model works well! Unsurpisingly, the probability of message5 being spam is quite high. But it's so funny that message4 turns out to be spam...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
